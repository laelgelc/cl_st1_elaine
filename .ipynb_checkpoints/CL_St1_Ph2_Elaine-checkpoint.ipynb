{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1 - Elaine\n",
    "# Video annotation proof-of-concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788c4af-1c7c-4f6d-8212-6cfded965e7c",
   "metadata": {},
   "source": [
    "## Downloading YouTube videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffec56-f136-429f-9004-4f947232b1b4",
   "metadata": {},
   "source": [
    "The most reliable way to download YouTube videos is to subscribe to YouTube Premium. Please refer to the following article on the Internet:\n",
    "\n",
    "- [7 Easy Ways to Download YouTube Videos](https://www.wikihow.com/Ways-to-Download-YouTube-Videos)\n",
    "\n",
    "For the purpose od this proof-of-concept the following resource was used:\n",
    "\n",
    "- [Open Video Downloader](https://github.com/StefanLobbenmeier/youtube-dl-gui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437ffdb-2470-4ba1-b183-5aa6a7f1d1e6",
   "metadata": {},
   "source": [
    "## Google Cloud Video Intelligence API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e5d59-4274-4560-b943-09f25310950f",
   "metadata": {},
   "source": [
    "Video Intelligence makes videos searchable, and discoverable, by extracting metadata with an easy to use API. You can now search every moment of every video file in your catalog and find every occurrence as well as its significance. It quickly annotates videos stored in Google Cloud Storage, or live-streamed, and helps you identify key nouns entities of your video, and when they occur within the video. Separate signal from noise, by retrieving relevant information at the video, shot or per frame.\n",
    "\n",
    "Please refer to:\n",
    "\n",
    "- [Google Cloud Video Intelligence API](https://cloud.google.com/video-intelligence?hl=en)\n",
    "- [Google Cloud Video Intelligence API documentation](https://cloud.google.com/video-intelligence/docs)\n",
    "- [Python Client for Video Intelligence](https://cloud.google.com/python/docs/reference/videointelligence/latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c8679-5971-4050-8656-266db5357153",
   "metadata": {},
   "source": [
    "## Required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a8065-d5fd-4ce4-9a6b-d9542f75b6eb",
   "metadata": {},
   "source": [
    "The following packages are required:\n",
    "\n",
    "- [Google Cloud Video Intelligence API](https://anaconda.org/conda-forge/google-cloud-videointelligence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d612d1-e2e2-48ff-a2f1-dd28038f6e80",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d166f32-a72a-4bb1-ba69-a4118a92464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from google.cloud import videointelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda82c0-d1ad-4050-beb1-2e8316ebd84f",
   "metadata": {},
   "source": [
    "## Label annotation test 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263d99a-4871-43ee-a747-0c0d83312c19",
   "metadata": {},
   "source": [
    "The video [The secrets of learning a new language ｜ Lýdia Machová ｜ TED](https://youtu.be/o_XVt5rdpFY?si=PSVl8l-XYC3zGlHe) was downloaded with `Open Video Downloader` with 360p24 video resolution and uploaded to a Google Cloud Storage bucket.\n",
    "\n",
    "- Filesize: 16.9 MB\n",
    "- Processing time: 36 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc811eca-06ac-49e9-9957-28b6c31bf26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-26 09:43:09\n",
      "\n",
      "Processing video for label annotations:\n",
      "\n",
      "Finished processing.\n",
      "Video label description: crowd\n",
      "\tLabel category description: people\n",
      "\tSegment 0: 0.0s to 645.375s\n",
      "\tConfidence: 0.3722715675830841\n",
      "\n",
      "\n",
      "Video label description: stage\n",
      "\tLabel category description: location\n",
      "\tSegment 0: 0.0s to 645.375s\n",
      "\tConfidence: 0.39481186866760254\n",
      "\n",
      "\n",
      "Video label description: audience\n",
      "\tLabel category description: people\n",
      "\tSegment 0: 0.0s to 645.375s\n",
      "\tConfidence: 0.4154287874698639\n",
      "\n",
      "\n",
      "Video label description: dress\n",
      "\tLabel category description: clothing\n",
      "\tSegment 0: 0.0s to 645.375s\n",
      "\tConfidence: 0.3249725103378296\n",
      "\n",
      "\n",
      "Video label description: television program\n",
      "\tSegment 0: 0.0s to 645.375s\n",
      "\tConfidence: 0.3009347915649414\n",
      "\n",
      "\n",
      "2024-06-26 09:43:45\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)\n",
    "\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "operation = video_client.annotate_video(\n",
    "    request={\n",
    "        'features': features,\n",
    "        'input_uri': 'gs://cl_st1_elaine/The secrets of learning a new language ｜ Lýdia Machová ｜ TED-(360p24).mp4',\n",
    "    }\n",
    ")\n",
    "print('\\nProcessing video for label annotations:')\n",
    "\n",
    "result = operation.result(timeout=180)\n",
    "print('\\nFinished processing.')\n",
    "\n",
    "# First result is retrieved because a single video was processed\n",
    "segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "for i, segment_label in enumerate(segment_labels):\n",
    "    print('Video label description: {}'.format(segment_label.entity.description))\n",
    "    for category_entity in segment_label.category_entities:\n",
    "        print(\n",
    "            '\\tLabel category description: {}'.format(category_entity.description)\n",
    "        )\n",
    "\n",
    "    for i, segment in enumerate(segment_label.segments):\n",
    "        start_time = (\n",
    "            segment.segment.start_time_offset.seconds\n",
    "            + segment.segment.start_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        end_time = (\n",
    "            segment.segment.end_time_offset.seconds\n",
    "            + segment.segment.end_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        positions = '{}s to {}s'.format(start_time, end_time)\n",
    "        confidence = segment.confidence\n",
    "        print('\\tSegment {}: {}'.format(i, positions))\n",
    "        print('\\tConfidence: {}'.format(confidence))\n",
    "    print('\\n')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c3b95-11d8-48c6-84f3-15ac602aa885",
   "metadata": {},
   "source": [
    "## Label annotation test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfc69e-dbc0-4a3f-b3a2-e9d6281900c8",
   "metadata": {},
   "source": [
    "The video [How language shapes the way we think ｜ Lera Boroditsky ｜ TED](https://youtu.be/RKK7wGAYP6k?si=XR6SwJs3YV5wEo7b) was downloaded with `Open Video Downloader` with 360p24 video resolution and uploaded to a Google Cloud Storage bucket.\n",
    "\n",
    "- Filesize: 22.9 MB\n",
    "- Processing time: 40 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ba08e7-0163-45d8-a7d7-2e2a5279c3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-26 09:43:56\n",
      "\n",
      "Processing video for label annotations:\n",
      "\n",
      "Finished processing.\n",
      "Video label description: fashion\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.41230762004852295\n",
      "\n",
      "\n",
      "Video label description: runway\n",
      "\tLabel category description: fashion\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.3841179311275482\n",
      "\n",
      "\n",
      "Video label description: stage\n",
      "\tLabel category description: location\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.39747747778892517\n",
      "\n",
      "\n",
      "Video label description: supermodel\n",
      "\tLabel category description: person\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.3505842983722687\n",
      "\n",
      "\n",
      "Video label description: fashion model\n",
      "\tLabel category description: person\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.4707123041152954\n",
      "\n",
      "\n",
      "Video label description: fashion show\n",
      "\tLabel category description: event\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.5205270051956177\n",
      "\n",
      "\n",
      "Video label description: dress\n",
      "\tLabel category description: clothing\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.5419418215751648\n",
      "\n",
      "\n",
      "Video label description: performance art\n",
      "\tLabel category description: entertainment\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.4507889747619629\n",
      "\n",
      "\n",
      "Video label description: model\n",
      "\tLabel category description: person\n",
      "\tSegment 0: 0.0s to 852.458333s\n",
      "\tConfidence: 0.6363872289657593\n",
      "\n",
      "\n",
      "2024-06-26 09:44:36\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)\n",
    "\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "operation = video_client.annotate_video(\n",
    "    request={\n",
    "        'features': features,\n",
    "        'input_uri': 'gs://cl_st1_elaine/How language shapes the way we think ｜ Lera Boroditsky ｜ TED-(360p24).mp4',\n",
    "    }\n",
    ")\n",
    "print('\\nProcessing video for label annotations:')\n",
    "\n",
    "result = operation.result(timeout=180)\n",
    "print('\\nFinished processing.')\n",
    "\n",
    "# First result is retrieved because a single video was processed\n",
    "segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "for i, segment_label in enumerate(segment_labels):\n",
    "    print('Video label description: {}'.format(segment_label.entity.description))\n",
    "    for category_entity in segment_label.category_entities:\n",
    "        print(\n",
    "            '\\tLabel category description: {}'.format(category_entity.description)\n",
    "        )\n",
    "\n",
    "    for i, segment in enumerate(segment_label.segments):\n",
    "        start_time = (\n",
    "            segment.segment.start_time_offset.seconds\n",
    "            + segment.segment.start_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        end_time = (\n",
    "            segment.segment.end_time_offset.seconds\n",
    "            + segment.segment.end_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        positions = '{}s to {}s'.format(start_time, end_time)\n",
    "        confidence = segment.confidence\n",
    "        print('\\tSegment {}: {}'.format(i, positions))\n",
    "        print('\\tConfidence: {}'.format(confidence))\n",
    "    print('\\n')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423da601-8837-411e-874c-f64989b1d5ff",
   "metadata": {},
   "source": [
    "## Label annotation test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bacb9-f6a6-4539-8cf4-c087da88961b",
   "metadata": {},
   "source": [
    "The video [With Spatial Intelligence, AI Will Understand the Real World ｜ Fei-Fei Li ｜ TED](https://youtu.be/y8NtMZ7VGmU?si=iaI5uVqjEpa5KgDs) was downloaded with `Open Video Downloader` with 360p24 video resolution and uploaded to a Google Cloud Storage bucket.\n",
    "\n",
    "- Filesize: 29.6 MB\n",
    "- Processing time: 41 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6840f195-e62d-4794-89ee-413d4741426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-26 09:44:44\n",
      "\n",
      "Processing video for label annotations:\n",
      "\n",
      "Finished processing.\n",
      "Video label description: stage\n",
      "\tLabel category description: location\n",
      "\tSegment 0: 0.0s to 911.66075s\n",
      "\tConfidence: 0.5873971581459045\n",
      "\n",
      "\n",
      "Video label description: performance\n",
      "\tLabel category description: event\n",
      "\tLabel category description: entertainment\n",
      "\tSegment 0: 0.0s to 911.66075s\n",
      "\tConfidence: 0.336836576461792\n",
      "\n",
      "\n",
      "Video label description: dress\n",
      "\tLabel category description: clothing\n",
      "\tSegment 0: 0.0s to 911.66075s\n",
      "\tConfidence: 0.3157428205013275\n",
      "\n",
      "\n",
      "Video label description: performing arts\n",
      "\tLabel category description: entertainment\n",
      "\tSegment 0: 0.0s to 911.66075s\n",
      "\tConfidence: 0.4768936038017273\n",
      "\n",
      "\n",
      "Video label description: public speaking\n",
      "\tLabel category description: person\n",
      "\tSegment 0: 0.0s to 911.66075s\n",
      "\tConfidence: 0.7045144438743591\n",
      "\n",
      "\n",
      "Video label description: orator\n",
      "\tLabel category description: person\n",
      "\tSegment 0: 0.0s to 911.66075s\n",
      "\tConfidence: 0.4069243371486664\n",
      "\n",
      "\n",
      "2024-06-26 09:45:25\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)\n",
    "\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "operation = video_client.annotate_video(\n",
    "    request={\n",
    "        'features': features,\n",
    "        'input_uri': 'gs://cl_st1_elaine/With Spatial Intelligence, AI Will Understand the Real World ｜ Fei-Fei Li ｜ TED-(360p24).mp4',\n",
    "    }\n",
    ")\n",
    "print('\\nProcessing video for label annotations:')\n",
    "\n",
    "result = operation.result(timeout=180)\n",
    "print('\\nFinished processing.')\n",
    "\n",
    "# First result is retrieved because a single video was processed\n",
    "segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "for i, segment_label in enumerate(segment_labels):\n",
    "    print('Video label description: {}'.format(segment_label.entity.description))\n",
    "    for category_entity in segment_label.category_entities:\n",
    "        print(\n",
    "            '\\tLabel category description: {}'.format(category_entity.description)\n",
    "        )\n",
    "\n",
    "    for i, segment in enumerate(segment_label.segments):\n",
    "        start_time = (\n",
    "            segment.segment.start_time_offset.seconds\n",
    "            + segment.segment.start_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        end_time = (\n",
    "            segment.segment.end_time_offset.seconds\n",
    "            + segment.segment.end_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        positions = '{}s to {}s'.format(start_time, end_time)\n",
    "        confidence = segment.confidence\n",
    "        print('\\tSegment {}: {}'.format(i, positions))\n",
    "        print('\\tConfidence: {}'.format(confidence))\n",
    "    print('\\n')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc398932-dd0f-44ba-9724-6d2b0bd3124c",
   "metadata": {},
   "source": [
    "## Label annotation test 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f394c1-7f15-490b-8d64-5b767409ff05",
   "metadata": {},
   "source": [
    "The video [Beautiful Interior Details ｜ Luxury Home Tour](https://youtu.be/zumJJUL_ruM?si=44HH9rbeF048sIid) was downloaded with `Open Video Downloader` with 360p30 video resolution and uploaded to a Google Cloud Storage bucket.\n",
    "\n",
    "- Filesize: 15.8 MB\n",
    "- Processing time: 21 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6783ff8c-680b-4bfb-aba4-140d71094330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-26 09:45:35\n",
      "\n",
      "Processing video for label annotations:\n",
      "\n",
      "Finished processing.\n",
      "Video label description: ceiling\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.39498665928840637\n",
      "\n",
      "\n",
      "Video label description: real estate\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.9126230478286743\n",
      "\n",
      "\n",
      "Video label description: property\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.9279853701591492\n",
      "\n",
      "\n",
      "Video label description: living room\n",
      "\tLabel category description: room\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.5740939974784851\n",
      "\n",
      "\n",
      "Video label description: building\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.8769206404685974\n",
      "\n",
      "\n",
      "Video label description: interior design\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.8824785351753235\n",
      "\n",
      "\n",
      "Video label description: estate\n",
      "\tLabel category description: building\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.6273171901702881\n",
      "\n",
      "\n",
      "Video label description: residential area\n",
      "\tLabel category description: geographical feature\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.49810314178466797\n",
      "\n",
      "\n",
      "Video label description: home improvement\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.3277931213378906\n",
      "\n",
      "\n",
      "Video label description: home\n",
      "\tLabel category description: building\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.8620946407318115\n",
      "\n",
      "\n",
      "Video label description: room\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.8365704417228699\n",
      "\n",
      "\n",
      "Video label description: suburb\n",
      "\tLabel category description: geographical feature\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.37019792199134827\n",
      "\n",
      "\n",
      "Video label description: house\n",
      "\tLabel category description: building\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.9237905740737915\n",
      "\n",
      "\n",
      "Video label description: wall\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.4651035666465759\n",
      "\n",
      "\n",
      "Video label description: architecture\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.4941582679748535\n",
      "\n",
      "\n",
      "Video label description: nature\n",
      "\tSegment 0: 0.0s to 269.702766s\n",
      "\tConfidence: 0.3207317292690277\n",
      "\n",
      "\n",
      "2024-06-26 09:45:56\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)\n",
    "\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "operation = video_client.annotate_video(\n",
    "    request={\n",
    "        'features': features,\n",
    "        'input_uri': 'gs://cl_st1_elaine/Beautiful Interior Details ｜ Luxury Home Tour-(360p30).mp4',\n",
    "    }\n",
    ")\n",
    "print('\\nProcessing video for label annotations:')\n",
    "\n",
    "result = operation.result(timeout=180)\n",
    "print('\\nFinished processing.')\n",
    "\n",
    "# First result is retrieved because a single video was processed\n",
    "segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "for i, segment_label in enumerate(segment_labels):\n",
    "    print('Video label description: {}'.format(segment_label.entity.description))\n",
    "    for category_entity in segment_label.category_entities:\n",
    "        print(\n",
    "            '\\tLabel category description: {}'.format(category_entity.description)\n",
    "        )\n",
    "\n",
    "    for i, segment in enumerate(segment_label.segments):\n",
    "        start_time = (\n",
    "            segment.segment.start_time_offset.seconds\n",
    "            + segment.segment.start_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        end_time = (\n",
    "            segment.segment.end_time_offset.seconds\n",
    "            + segment.segment.end_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        positions = '{}s to {}s'.format(start_time, end_time)\n",
    "        confidence = segment.confidence\n",
    "        print('\\tSegment {}: {}'.format(i, positions))\n",
    "        print('\\tConfidence: {}'.format(confidence))\n",
    "    print('\\n')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba3afb-b19f-42cc-b1f8-dd73469090bd",
   "metadata": {},
   "source": [
    "## Label annotation test 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23834f31-16f3-4948-98bd-f82cedb3a453",
   "metadata": {},
   "source": [
    "The video [This Ultra Modern Tiny Eco Home Will Blow Your Mind ｜ See Inside](https://youtu.be/eRBNnfXXF4w?si=C8iBeDuN70T0z6tC) was downloaded with `Open Video Downloader` with 360p25 video resolution and uploaded to a Google Cloud Storage bucket.\n",
    "\n",
    "- Filesize: 38.8 MB\n",
    "- Processing time: 42 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd54ed32-43f4-4283-8294-01f0b4c4518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-26 09:46:06\n",
      "\n",
      "Processing video for label annotations:\n",
      "\n",
      "Finished processing.\n",
      "Video label description: room\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.7402945160865784\n",
      "\n",
      "\n",
      "Video label description: property\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.7475116848945618\n",
      "\n",
      "\n",
      "Video label description: architecture\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.6082988977432251\n",
      "\n",
      "\n",
      "Video label description: tree\n",
      "\tLabel category description: plant\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.31196892261505127\n",
      "\n",
      "\n",
      "Video label description: house\n",
      "\tLabel category description: building\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.8403676748275757\n",
      "\n",
      "\n",
      "Video label description: nature\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.4699305295944214\n",
      "\n",
      "\n",
      "Video label description: wilderness\n",
      "\tLabel category description: geographical feature\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.48006629943847656\n",
      "\n",
      "\n",
      "Video label description: home\n",
      "\tLabel category description: building\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.7681269645690918\n",
      "\n",
      "\n",
      "Video label description: building\n",
      "\tSegment 0: 0.0s to 673.4s\n",
      "\tConfidence: 0.8769206404685974\n",
      "\n",
      "\n",
      "2024-06-26 09:46:48\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)\n",
    "\n",
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "operation = video_client.annotate_video(\n",
    "    request={\n",
    "        'features': features,\n",
    "        'input_uri': 'gs://cl_st1_elaine/This Ultra Modern Tiny Eco Home Will Blow Your Mind ｜ See Inside-(360p25).mp4',\n",
    "    }\n",
    ")\n",
    "print('\\nProcessing video for label annotations:')\n",
    "\n",
    "result = operation.result(timeout=180)\n",
    "print('\\nFinished processing.')\n",
    "\n",
    "# First result is retrieved because a single video was processed\n",
    "segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "for i, segment_label in enumerate(segment_labels):\n",
    "    print('Video label description: {}'.format(segment_label.entity.description))\n",
    "    for category_entity in segment_label.category_entities:\n",
    "        print(\n",
    "            '\\tLabel category description: {}'.format(category_entity.description)\n",
    "        )\n",
    "\n",
    "    for i, segment in enumerate(segment_label.segments):\n",
    "        start_time = (\n",
    "            segment.segment.start_time_offset.seconds\n",
    "            + segment.segment.start_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        end_time = (\n",
    "            segment.segment.end_time_offset.seconds\n",
    "            + segment.segment.end_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        positions = '{}s to {}s'.format(start_time, end_time)\n",
    "        confidence = segment.confidence\n",
    "        print('\\tSegment {}: {}'.format(i, positions))\n",
    "        print('\\tConfidence: {}'.format(confidence))\n",
    "    print('\\n')\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7133238-ef36-40f8-b884-44293ec2a67d",
   "metadata": {},
   "source": [
    "## Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578f8f5-9dfe-4507-a5f5-ad24d92eed08",
   "metadata": {},
   "source": [
    "### Processing time ratio (maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4ff69-caf9-4da0-9158-082357b1b0df",
   "metadata": {},
   "source": [
    "- 2.13 s/MB maximum on this sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7ed0e-faf4-42cf-9c4c-87fdb7b08276",
   "metadata": {},
   "source": [
    "### Filesize of typical TED videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d9a8d-de8a-4dda-84ac-0941f0a048d6",
   "metadata": {},
   "source": [
    "- 360p25 video resolution\n",
    "- 23.13 MB on average for typical TED videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e722c9-32ac-42a2-9b61-5aef75516499",
   "metadata": {},
   "source": [
    "### Processing time per TED video file (maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124a4fa-8126-4a13-a663-d0f3a46df0e4",
   "metadata": {},
   "source": [
    "- 23.13 * 2.13 = 49.28 s maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161b264-c77d-4334-aff0-22485f5ab22a",
   "metadata": {},
   "source": [
    "### Processing time for 200 TED video files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2afa9-f78a-44fc-9e18-18fe378f65ec",
   "metadata": {},
   "source": [
    "- (49.28 * 200) / 60 = 164.26 min = 2,74 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef765da-395c-46d0-a5a7-3be9073df470",
   "metadata": {},
   "source": [
    "### Storage space for 200 TED video files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4672f3-f85a-42b7-8479-93fe3c8be27f",
   "metadata": {},
   "source": [
    "- 4.627 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd801562-10e9-44c5-9874-02964718ee41",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a517c-9a19-468f-a058-b90ff06f2373",
   "metadata": {},
   "source": [
    "Please refer to [Google Cloud Video Intelligence API](https://console.cloud.google.com/apis/library/videointelligence.googleapis.com) and click on the `PRICING` tab and choose `Label Detection`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78f9ac-9ed6-49ac-9131-0e227defe944",
   "metadata": {},
   "source": [
    "## Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579683fd-179b-4bb5-9e7d-96af42a40182",
   "metadata": {},
   "source": [
    "### Quickstart: Annotate a video by using client libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a0010-f307-437d-a839-e9825adc758a",
   "metadata": {},
   "source": [
    "Please refer to [Annotate a video by using client libraries](https://cloud.google.com/video-intelligence/docs/annotate-video-client-libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d127ac0c-954d-4396-9ba0-1df4c60e35db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing video for label annotations:\n",
      "\n",
      "Finished processing.\n",
      "Video label description: kitten\n",
      "\tLabel category description: cat\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.3615228831768036\n",
      "\n",
      "\n",
      "Video label description: maine coon\n",
      "\tLabel category description: cat\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.32171761989593506\n",
      "\n",
      "\n",
      "Video label description: small to medium sized cats\n",
      "\tLabel category description: mammal\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.7987512946128845\n",
      "\n",
      "\n",
      "Video label description: pet\n",
      "\tLabel category description: animal\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.8389395475387573\n",
      "\n",
      "\n",
      "Video label description: tabby cat\n",
      "\tLabel category description: cat\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.30844953656196594\n",
      "\n",
      "\n",
      "Video label description: cat\n",
      "\tLabel category description: pet\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.997473955154419\n",
      "\n",
      "\n",
      "Video label description: whiskers\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.3001704514026642\n",
      "\n",
      "\n",
      "Video label description: animal\n",
      "\tSegment 0: 0.0s to 14.84s\n",
      "\tConfidence: 0.9441419243812561\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "video_client = videointelligence.VideoIntelligenceServiceClient()\n",
    "features = [videointelligence.Feature.LABEL_DETECTION]\n",
    "operation = video_client.annotate_video(\n",
    "    request={\n",
    "        'features': features,\n",
    "        'input_uri': 'gs://cloud-samples-data/video/cat.mp4',\n",
    "    }\n",
    ")\n",
    "print('\\nProcessing video for label annotations:')\n",
    "\n",
    "result = operation.result(timeout=180)\n",
    "print('\\nFinished processing.')\n",
    "\n",
    "# First result is retrieved because a single video was processed\n",
    "segment_labels = result.annotation_results[0].segment_label_annotations\n",
    "for i, segment_label in enumerate(segment_labels):\n",
    "    print('Video label description: {}'.format(segment_label.entity.description))\n",
    "    for category_entity in segment_label.category_entities:\n",
    "        print(\n",
    "            '\\tLabel category description: {}'.format(category_entity.description)\n",
    "        )\n",
    "\n",
    "    for i, segment in enumerate(segment_label.segments):\n",
    "        start_time = (\n",
    "            segment.segment.start_time_offset.seconds\n",
    "            + segment.segment.start_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        end_time = (\n",
    "            segment.segment.end_time_offset.seconds\n",
    "            + segment.segment.end_time_offset.microseconds / 1e6\n",
    "        )\n",
    "        positions = '{}s to {}s'.format(start_time, end_time)\n",
    "        confidence = segment.confidence\n",
    "        print('\\tSegment {}: {}'.format(i, positions))\n",
    "        print('\\tConfidence: {}'.format(confidence))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b16a5c-d348-420c-9c4e-2fdffc241d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
